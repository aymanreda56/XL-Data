{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sustained-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.ml\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler,StringIndexer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "import sys; sys.path.append(\"../../\")\n",
    "from DataPreprocessing.DataPreprocessing import read_data,encode_categ_features,remove_useless_col\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d96bafd",
   "metadata": {},
   "source": [
    "# Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continent-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master='local')\n",
    "spark = SparkSession.builder.appName(\"InstallationsPrediction\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "638ae28a",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handled-basketball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('App Name', 'string'),\n",
       " ('App Id', 'string'),\n",
       " ('Category', 'string'),\n",
       " ('Rating', 'float'),\n",
       " ('Rating Count', 'int'),\n",
       " ('Installs', 'string'),\n",
       " ('Minimum Installs', 'int'),\n",
       " ('Maximum Installs', 'int'),\n",
       " ('Free', 'string'),\n",
       " ('Price', 'float'),\n",
       " ('Size', 'string'),\n",
       " ('Minimum Android', 'string'),\n",
       " ('Developer Id', 'string'),\n",
       " ('Developer Email', 'string'),\n",
       " ('Released', 'string'),\n",
       " ('Last Updated', 'string'),\n",
       " ('Content Rating', 'string'),\n",
       " ('Ad Supported', 'string'),\n",
       " ('In App Purchases', 'string'),\n",
       " ('Editors Choice', 'string')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= read_data(spark, features='all')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c276bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Category', 'string'),\n",
       " ('Rating', 'float'),\n",
       " ('Rating Count', 'int'),\n",
       " ('Installs', 'string'),\n",
       " ('Minimum Installs', 'int'),\n",
       " ('Maximum Installs', 'int'),\n",
       " ('Free', 'string'),\n",
       " ('Price', 'float'),\n",
       " ('Size', 'string'),\n",
       " ('Minimum Android', 'string'),\n",
       " ('Developer Id', 'string'),\n",
       " ('Developer Email', 'string'),\n",
       " ('Released', 'string'),\n",
       " ('Last Updated', 'string'),\n",
       " ('Content Rating', 'string'),\n",
       " ('Ad Supported', 'string'),\n",
       " ('In App Purchases', 'string'),\n",
       " ('Editors Choice', 'string')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "App Name, App Id, Rating, Rating Count, Released, Last Updated, Content Rating are not interesting here for max installations prediction,\n",
    "so we can remove them safely\n",
    "'''\n",
    "\n",
    "useless_cols= ['App Name','App Id']\n",
    "df= remove_useless_col(df,useless_cols)\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "happy-aquarium",
   "metadata": {},
   "source": [
    "# Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40e60bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_categ_cols= ['Category', 'Ad Supported', 'In App Purchases', 'Editors Choice',\\\n",
    "                  'Free', 'Size', \"Minimum Android\",\"Developer Id\",\"Developer Email\",\\\n",
    "                    'Rating','Rating Count',\\\n",
    "               'Released','Last Updated','Content Rating','Installs','Minimum Installs']\n",
    "\n",
    "df= encode_categ_features(df,interesting_categ_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eef5d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Maximum Installs\"\n",
    "column_names = df.columns\n",
    "\n",
    "# Remove the column to move from the list of column names\n",
    "column_names.remove(label)\n",
    "\n",
    "# Reorder the list of column names so that the column to move is at the end\n",
    "new_column_order = column_names + [label]\n",
    "\n",
    "# Use the new column order to select the columns in the DataFrame,\n",
    "# and then add the column to move to the end using withColumn()\n",
    "df = df.select(*new_column_order).withColumn(label, col(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "critical-grenada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Price', 'Category', 'Ad Supported', 'In App Purchases', 'Editors Choice', 'Free', 'Size', 'Minimum Android', 'Developer Id', 'Developer Email', 'Rating', 'Rating Count', 'Released', 'Last Updated', 'Content Rating', 'Installs', 'Minimum Installs']\n"
     ]
    }
   ],
   "source": [
    "required_features = df.columns[:-1]      #all except the target variable which is at the last index\n",
    "print(required_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "outer-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=required_features,outputCol='Features')\n",
    "vec_df = vec_assembler.setHandleInvalid(\"skip\").transform(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "circular-treaty",
   "metadata": {},
   "source": [
    "# Splitting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "polished-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = vec_df.select(['Features', 'Maximum Installs']).randomSplit([0.7,0.3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "stupid-cocktail",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "active-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='Features',labelCol='Maximum Installs', regParam=0.3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "atlantic-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4747.646864\n",
      "r2: 0.349121\n"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "#just some training metrics\n",
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "confidential-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-------------------+\n",
      "|            Features|Maximum Installs|         prediction|\n",
      "+--------------------+----------------+-------------------+\n",
      "|(17,[0,1,2,5,6,7,...|             238| -842.1016698885486|\n",
      "|(17,[0,1,2,5,6,7,...|             218| -573.1449446455225|\n",
      "|(17,[0,1,2,5,6,7,...|             130|-2381.4550009059467|\n",
      "|(17,[0,1,2,5,6,7,...|             314| -2159.499181247639|\n",
      "|(17,[0,1,2,5,6,7,...|             214| -943.7404244715199|\n",
      "+--------------------+----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_model.transform(test_df)\n",
    "y_pred.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bcc55d9",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "continuing-george",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.349139\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"Maximum Installs\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69c4cb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 4772.44\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dde13580",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52e76a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while training or evaluating Decision Tree Regressor: requirement failed: DecisionTree requires maxBins (= 32) to be at least as large as the number of values in each categorical feature, but categorical feature 9 has 809942 values. Consider removing this and other categorical features with a large number of values, or add more training examples.\n",
      "Error occurred while training or evaluating Random Forest Regressor: requirement failed: DecisionTree requires maxBins (= 32) to be at least as large as the number of values in each categorical feature, but categorical feature 9 has 809942 values. Consider removing this and other categorical features with a large number of values, or add more training examples.\n",
      "Error occurred while training or evaluating Gradient Boosted Tree Regressor: requirement failed: DecisionTree requires maxBins (= 32) to be at least as large as the number of values in each categorical feature, but categorical feature 9 has 809942 values. Consider removing this and other categorical features with a large number of values, or add more training examples.\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.regression import DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
    "# from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# # Decision Tree Regressor\n",
    "# try:\n",
    "#     dt= DecisionTreeRegressor(featuresCol='Features',labelCol='Maximum Installs', maxDepth=3)\n",
    "#     dt_model = dt.fit(train_df)\n",
    "#     y_pred = dt_model.transform(test_df)\n",
    "#     y_pred.show(5)\n",
    "#     dt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "#                     labelCol=\"Maximum Installs\",metricName=\"r2\")\n",
    "#     print(\"R Squared (R2) on test data = %g\" % dt_evaluator.evaluate(y_pred))\n",
    "#     test_result = dt_model.evaluate(test_df)\n",
    "#     print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)\n",
    "# except Exception as e:\n",
    "#     print(\"Error occurred while training or evaluating Decision Tree Regressor:\", e)\n",
    "\n",
    "# # Random Forest Regressor\n",
    "# try:\n",
    "#     rf = RandomForestRegressor(featuresCol='Features',labelCol='Maximum Installs', numTrees=100)\n",
    "#     rf_model = rf.fit(train_df)\n",
    "#     y_pred = rf_model.transform(test_df)\n",
    "#     y_pred.show(5)\n",
    "#     rf_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "#                     labelCol=\"Maximum Installs\",metricName=\"r2\")\n",
    "#     print(\"R Squared (R2) on test data = %g\" % rf_evaluator.evaluate(y_pred))\n",
    "#     test_result = rf_model.evaluate(test_df)\n",
    "#     print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)\n",
    "# except Exception as e:\n",
    "#     print(\"Error occurred while training or evaluating Random Forest Regressor:\", e)\n",
    "\n",
    "# # Gradient Boosted Tree Regressor\n",
    "# try:\n",
    "#     gbt = GBTRegressor(featuresCol='Features',labelCol='Maximum Installs', maxIter=10)\n",
    "#     gbt_model = gbt.fit(train_df)\n",
    "#     y_pred = gbt_model.transform(test_df)\n",
    "#     y_pred.show(5)\n",
    "#     gbt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "#                     labelCol=\"Maximum Installs\",metricName=\"r2\")\n",
    "#     print(\"R Squared (R2) on test data = %g\" % gbt_evaluator.evaluate(y_pred))\n",
    "#     test_result = gbt_model.evaluate(test_df)\n",
    "#     print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)\n",
    "# except Exception as e:\n",
    "#     print(\"Error occurred while training or evaluating Gradient Boosted Tree Regressor:\", e)\n",
    "# # from pyspark.ml.regression import AFTSurvivalRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b66a3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Feature Importance\n",
    "# dt_model.featureImportances\n",
    "\n",
    "# #notice that Feature at index 0 has higher importance, this feature is the 'Rating Count'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "496bc3dc",
   "metadata": {},
   "source": [
    "## Gradient-Boosted Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.regression import GBTRegressor\n",
    "# gbt = GBTRegressor(featuresCol = 'Features', labelCol = 'Maximum Installs', maxIter=10, maxBins=48) #same as above, maxbins is set just to avoid an error I dont understand\n",
    "# # maxIter is just a hyperparameter we put by hand\n",
    "# gbt_model = gbt.fit(train_df)\n",
    "# gbt_predictions = gbt_model.transform(test_df)\n",
    "# gbt_predictions.select('prediction', 'Maximum Installs', 'Features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087cca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbt_evaluator = RegressionEvaluator(\n",
    "#     labelCol=\"Maximum Installs\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "# rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "# print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
