{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sustained-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.ml\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler,StringIndexer\n",
    "\n",
    "import sys; sys.path.append(\"../\")\n",
    "from DataPreprocessing.DataPreprocessing import read_data,encode_categ_features,remove_useless_col\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d96bafd",
   "metadata": {},
   "source": [
    "# Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continent-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master='local')\n",
    "spark = SparkSession.builder.appName(\"InstallationsPrediction\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "638ae28a",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handled-basketball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting outliers...\n",
      "Number of outliers in Rating: 0 (0.00%)\n",
      "Number of outliers in Rating Count: 388994 (16.82%)\n",
      "Number of outliers in Minimum Installs: 260554 (11.27%)\n",
      "Number of outliers in Maximum Installs: 407678 (17.63%)\n",
      "Number of outliers in Price: 44943 (1.94%)\n",
      "Number of rows before removing outliers: 2312944\n",
      "Number of rows after removing those having more than 1 outlier in its columns: 1961130\n",
      "Removing useless columns...\n",
      "Handling missing values...\n",
      "Total Number of rows : 1961130\n",
      "Number of rows after dropping nulls: 1954764\n",
      "Total Number of rows : 1954764\n",
      "Total Number of rows : 1954764\n",
      "Converting size to bytes...\n",
      "Converted all sizes to Bytes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('App Name', 'string'),\n",
       " ('App Id', 'string'),\n",
       " ('Category', 'string'),\n",
       " ('Rating', 'float'),\n",
       " ('Rating Count', 'int'),\n",
       " ('Installs', 'string'),\n",
       " ('Minimum Installs', 'int'),\n",
       " ('Maximum Installs', 'int'),\n",
       " ('Free', 'string'),\n",
       " ('Price', 'float'),\n",
       " ('Size', 'string'),\n",
       " ('Minimum Android', 'string'),\n",
       " ('Developer Id', 'string'),\n",
       " ('Developer Email', 'string'),\n",
       " ('Released', 'string'),\n",
       " ('Last Updated', 'string'),\n",
       " ('Content Rating', 'string'),\n",
       " ('Ad Supported', 'string'),\n",
       " ('In App Purchases', 'string'),\n",
       " ('Editors Choice', 'string')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= read_data(spark, features='all')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c276bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Category', 'string'),\n",
       " ('Maximum Installs', 'int'),\n",
       " ('Free', 'string'),\n",
       " ('Price', 'float'),\n",
       " ('Size', 'string'),\n",
       " ('Minimum Android', 'string'),\n",
       " ('Developer Id', 'string'),\n",
       " ('Developer Email', 'string'),\n",
       " ('Ad Supported', 'string'),\n",
       " ('In App Purchases', 'string'),\n",
       " ('Editors Choice', 'string')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "App Name, App Id, Rating, Rating Count, Released, Last Updated, Content Rating are not interesting here for max installations prediction,\n",
    "so we can remove them safely\n",
    "'''\n",
    "\n",
    "useless_cols= ['App Name','App Id','Rating','Rating Count',\\\n",
    "               'Released','Last Updated','Content Rating','Installs','Minimum Installs']\n",
    "df= remove_useless_col(df,useless_cols)\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "happy-aquarium",
   "metadata": {},
   "source": [
    "# Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40e60bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_categ_cols= ['Category', 'Ad Supported', 'In App Purchases', 'Editors Choice',\\\n",
    "                  'Free', 'Size', \"Minimum Android\",\"Developer Id\",\"Developer Email\"]\n",
    "\n",
    "df= encode_categ_features(df,interesting_categ_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eef5d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange to make label the last column\n",
    "df = df.select('Price','Category', 'Ad Supported', 'In App Purchases', 'Editors Choice',\\\n",
    "            'Free', 'Size', \"Minimum Android\",\"Developer Id\",\"Developer Email\",\\\n",
    "            'Maximum Installs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "critical-grenada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Price', 'Category', 'Ad Supported', 'In App Purchases', 'Editors Choice', 'Free', 'Size', 'Minimum Android', 'Developer Id', 'Developer Email']\n"
     ]
    }
   ],
   "source": [
    "required_features = df.columns[:-1]      #all except the target variable which is at the last index\n",
    "print(required_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "outer-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=required_features,outputCol='Features')\n",
    "vec_df = vec_assembler.setHandleInvalid(\"skip\").transform(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "circular-treaty",
   "metadata": {},
   "source": [
    "# Splitting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "polished-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = vec_df.select(['Features', 'Maximum Installs']).randomSplit([0.7,0.3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "stupid-cocktail",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "active-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='Features',labelCol='Maximum Installs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "atlantic-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5789.517479\n",
      "r2: 0.033304\n"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "#just some training metrics\n",
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "confidential-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+------------------+\n",
      "|            Features|Maximum Installs|        prediction|\n",
      "+--------------------+----------------+------------------+\n",
      "|(10,[0,1,5,8,9],[...|               8|   68.136875719925|\n",
      "|(10,[0,1,5,8,9],[...|               2|103.00643060375387|\n",
      "|(10,[0,1,5,8,9],[...|             475| 85.52440582609961|\n",
      "|(10,[0,1,5,8,9],[...|             422| 85.47926251734839|\n",
      "|(10,[0,5,6,8,9],[...|              14| 37.53743873067924|\n",
      "+--------------------+----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_model.transform(test_df)\n",
    "y_pred.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bcc55d9",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continuing-george",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.0319308\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"Maximum Installs\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69c4cb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 5812\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dde13580",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52e76a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(featuresCol ='Features', labelCol = 'Maximum Installs', maxBins=48)   #setting a larger maxbins(default=32) is an ad-hoc step just to solve an error I dont understand :)\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"Maximum Installs\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66a3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "dt_model.featureImportances\n",
    "\n",
    "#notice that Feature at index 0 has higher importance, this feature is the 'Rating Count'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "496bc3dc",
   "metadata": {},
   "source": [
    "## Gradient-Boosted Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'Features', labelCol = 'Maximum Installs', maxIter=10, maxBins=48) #same as above, maxbins is set just to avoid an error I dont understand\n",
    "# maxIter is just a hyperparameter we put by hand\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'Maximum Installs', 'Features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087cca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"Maximum Installs\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
